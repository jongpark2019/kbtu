{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jongpark2019/kbtu/blob/main/LogisticRegression_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEmOZPUVX_h1"
      },
      "source": [
        "# Logistic Regression\n",
        "<p align=\"justify\">In this practice, we introduce how to implement logistic regression with Python. The logistic regression model will be optimized using SGD algorithm which was introduced in SGD_Practice[].</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory of Logistic Regression\n",
        "<p align=\"justify\">The logis regression is formally defined as: given N samples in a dataset $\\{(x_i,y_i ):i=1,2,..,n\\}$, find a function $h_w (x)$ that minimizes the cost (or loss) function $L(w)$, cross-entropy (CE) error function: \n",
        "$$\n",
        "L(w)=  -\\frac{1}{n} \\sum_{i=1}^{n}(y_i \\log h_w (x_i) + (1 - y_i )\\log(1- h_w (x_i))) \n",
        "$$\n",
        "Here, the logistic function $h_w(x) = \\frac{1}{1+e^{-wx}}$ is used for prediction. Prediciton is actually a binary classification with true or false. If $h_w(x)$ > threshold, the prediction is true, otherwise the prediction is false. As for the linear regression, we would like to find the value of $w$ which minimizes the cost function $L(w)$ on the given dataset. Note that log in the equation $L(w)$ means the natural logarithm. The logistic function is also called sigmoid function. Below, we plot the $\\sigma(z)$ where $z = wx$. </p>"
      ],
      "metadata": {
        "id": "-rrYYtQ2kx21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import matplotlib, numpy and math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "z = np.linspace(-10, 10, 100)\n",
        "sigma_z = 1/(1 + np.exp(-z))\n",
        "  \n",
        "plt.plot(z, sigma_z)\n",
        "plt.xlabel(\"z\")\n",
        "plt.ylabel(\"Sigmoid(z)\")\n",
        "  \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "VHDoxtpFRzv1",
        "outputId": "1ddbdcb8-0207-482d-9d06-6935817f410f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example\n",
        "\n",
        "<p align=\"justify\">For the example of logistic regression with SGD, let’s consider a toy example of taking test to get a driver licence. The test usually consists of both written test and practice test. Here, it is assumed that you already passed the practice test, and you need to take a written test. The dataset in Table below shows the pass (1) or fail (0) results, based only on the score of the written test. The questions is that when you get the score 60, marked X in the graph shown below, will you pass or fail for getting the lincence ? It is also assumed that the score threshold determining fail/pass is not open, so you don't know whether you will pass or fail with the score 60. This kind of problem is known as logistic regression. Contrasting to the linear regression, you want to predict Pass/Fail (or True/False).  \n",
        "\n",
        "| x (score)| y (pass or fail) | \n",
        "|:----------:|:-------------:|\n",
        "| 30 |  0 | \n",
        "| 90 | 1  |  \n",
        "| 50 | 0 |\n",
        "| 65 |  1 |\n",
        "| 70 |  1 |\n",
        "| 40 |  0 |\n",
        "\n",
        "</p>\n",
        "\n",
        "Next, we illustrate the logistic regression using SGD algorithm, step by step.  The dataset is plotted at the figure below where x and y are score and pass/fail for getting driver licence, respectively. Note that for the computational efficiencly, the values of score are divided by 10.\n",
        "</p>"
      ],
      "metadata": {
        "id": "b82GyjLwtK3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset\n",
        "dataset = np.array([[.30,  0],\n",
        "                    [.90,  1],\n",
        "                    [.50,  0],\n",
        "                    [.65,  1],\n",
        "                    [.70,  1],\n",
        "                    [.40,  0]])\n",
        "x = dataset[:, 0]\n",
        "y = dataset[:, 1]\n",
        " \n",
        "# Show the dataset\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.title('score (x) vs fail/pass (y)')\n",
        "plt.scatter(x, y, color = \"m\", marker = \"o\", s = 30)\n",
        "plt.scatter(0.6, 0.5, color = \"b\", marker = \"x\", s = 70)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WCu_LMT5FP5T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b933b311-3bfc-450c-9aec-a0f026250106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUpkPOn_X_iD"
      },
      "source": [
        "## Minimizing the Cross-Entropy Loss Function\n",
        "<p align=\"justify\"> With a logistic function for the hypothesis function, i.e., $h_w(x) = \\frac{1}{1+e^{-wx}}$, we get the loss fuction for logistic regression with $L(w)$:\n",
        "$$\n",
        "L(w)=  -\\frac{1}{n} \\sum_{i=1}^{n}(y_i\\log \\sigma(wx_i) + (1 - y_i )\\log(1- \\sigma(wx_i))) \n",
        "$$\n",
        "where $\\sigma(wx_i)$ is defined as $\\frac{1}{1+e^{-wx}}$.\n",
        "Now, we want to optimize the model  $\\sigma(wx_i)$ by adjusting the parameter $w$ so that the cross-entropy error (CE) along all samples in the dataset is minimized. We apply the SGD (stochastic gradient descent) algorithm to obtain the optimal solution. As descriced previously[], the SGD works by taking the gradient of the loss function $L(w)$ with respect to the parameter $w$ at a specific position on the loss function, and updates the parameters in the direction of the negative gradient. The parameter $w$ is iteratively updated by taking steps proportional to the negative of the gradient:\n",
        "$w ← w - η∇L(w)$. Here, $\\nabla L(w)$ is defined as:\n",
        "$$\n",
        "\\nabla L(w) = \\frac{\\partial L(w)}{\\partial w}\n",
        "$$\n",
        "For notational simplification, let $o_i = \\sigma(wx_i)$ and $z_i = wx_i$. Then, $o_i = \\sigma(z_i) = \\frac{1}{1+e^{-z_i}}$. In other words, $o_i$ is the predicted output for the sample input $x_i$. Then, \n",
        "$$\n",
        "L(w)=  -\\frac{1}{n} \\sum_{i=1}^{n}(y_i\\log o_i + (1 - y_i )\\log(1- o_i)) \n",
        "$$\n",
        "Using the chain rule of differential equation $[g(h(x))]^{'}$ = $g^{'}(h(x))h^{'}(x)$,\n",
        "$$\n",
        "\\frac{\\partial L(w)}{\\partial w} = \\sum_{i=1}^{n}\\frac{\\partial L(w)}{\\partial o_i}\\frac{\\partial o_i}{\\partial z_i}\\frac{\\partial z_i}{\\partial w}\n",
        "$$\n",
        "For a specific sample $k$, we can canculate that: \n",
        "$$\n",
        "\\frac{\\partial L(w)}{\\partial o_k}  =  -\\frac{1}{n} \\left\\{ \\frac {y_k \\partial \\log o_k}{\\partial o_k} + \\frac {(1-y_k)\\partial \\log(1- o_k)}{\\partial o_k}  \\right\\}\n",
        "$$\n",
        "This results in:\n",
        "$$\n",
        "\\frac{\\partial L(w)}{\\partial o_k}  = -\\frac{1}{n} \\left\\{\\frac{y_k}{o_k} - \n",
        "\\frac{1-y_k}{1-o_k}\\right\\}\n",
        "$$\n",
        "Also, for a specific sample $k$,  \n",
        "$$\n",
        "\\frac{\\partial o_k}{\\partial z_k} = \\frac {\\partial (\\frac {1}{1+e^{-z_k}})}{\\partial z_k} = \\frac {e^{-z_k}}{(1+e^{-z_k})^2} = \\frac {1}{(1+e^{-z_k})}(1 - \\frac {1}{(1+e^{-z_k})}) = o_k (1 - o_k)\n",
        "$$\n",
        "And since $z_k = wx_k$, we obtain:\n",
        "$$\\frac{\\partial z_k}{\\partial w} = x_k$$\n",
        "So, by simple calculation, we obtain:\n",
        "$$\n",
        "\\frac{\\partial L(w)}{\\partial w} = -\\frac{1}{n} \\sum_{i=1}^{n} \\left\\{\\frac{y_i}{o_i} - \\frac{1-y_i}{1-o_i}\\right\\} o_i (1 - o_i)  x_i = \\frac{1}{n} \\sum_{i=1}^{n}(o_i - y_i ) x_i\n",
        "$$\n",
        "Finally, the full update function $\\nabla L(w)$ for the entire dataset will become:\n",
        "$$\n",
        "\\nabla L(w) = \\frac{\\partial L(w)}{\\partial w} = \\frac{1}{n} \\sum_{i=1}^{n}(o_i - y_i )x_i = \\frac {1}{n} \\sum_{i=1}^{n}(\\sigma(wx_i) - y_i )x_i \n",
        "$$\n",
        "This formula is actually identical to $\\nabla L(w)$ for the linear regression, except that $o_i$ is different. For the case of linear regression, $o_i$ = $wx_i$ []. Note that the formula is for batch gradient descent, and  In other words, all the gradients are caculated and summed up before updating the parameter $w$.  Using mini-batch SGD, a set of mini-batches which are selected randomly can be processed for both train and inference. As in the case of linear regression, $(o_i - y_i ) x_i$ is the gradient for the sample $i$. For online SGD, the weight is updated with $\\nabla L(w)$ = $(o_i - y_i ) x_i$. </p> \n",
        "\n",
        "<p align=\"justify\">Below, we have implemented the logistic regression with Python, using gradient descent agorithm.  </p>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of Logistic Regression with Mini-batch SGD\n",
        "<p align=\"justify\"> SGD first randomly divides the datset into mini-batches and for each minibatch, the gradient is computed and all parameters are updated. After all mini-batches are used, the next iteration can start until the stopping criteria are met. The stopping criteria usually checks for the convergence. \n",
        "Comparing with the code of the linear regression with SGD, the hypothesis function h(x,w) and the loss function are changed. The sigmoid function is newly added for calculation of h(x,w). Function gradient() and function SGD() are identical to those for linear regression [].</p>"
      ],
      "metadata": {
        "id": "O6YZZBXF3hd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(45) # set the seed value\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\" Logistic function \"\"\"\n",
        "    return 1.0/(1+ np.exp(-x))\n",
        "\n",
        "def h(x, w):\n",
        "    \"\"\"Hypothesis function h(x) = sigmoid (x * w)\"\"\"\n",
        "    return sigmoid(x * w)\n",
        "\n",
        "def loss(o, y):\n",
        "    \"\"\"Cross-entropy error function\"\"\"\n",
        "    return -np.mean(y*np.log(o) + (1-y)*np.log(1-o)) # np.log is natural logarithm\n",
        "\n",
        "\n",
        "def gradient(x, w, y):\n",
        "    \"\"\"Gradient function\"\"\"\n",
        "    return x * (h(x, w) - y)\n",
        "\n",
        "def SGD(n_iter):\n",
        "    \"\"\" Mini-batch gradient descent optimization\"\"\"\n",
        "\n",
        "    # Initialize learning rate and weight \n",
        "    eta = 0.7 # learning rate\n",
        "    w = 0.05  # Initialize weight\n",
        "    data = dataset.copy() # get a copy of dataset for shuffling\n",
        "\n",
        "    # Perform mini-batch SGD optimization\n",
        "    for i in range(n_iter):\n",
        "\n",
        "        np.random.shuffle(data) # Randomize the dataset\n",
        "        x = data[:, 0] # Get input data\n",
        "        y = data[:, 1] # Get target data\n",
        "        loss_sum = 0  \n",
        "\n",
        "        for j in range(num_batch): # Iterate over mini-batches of dataset\n",
        "            x_batch = x[batch_size * j: batch_size * (j+1)]    # Get a mini-batch of input data x\n",
        "            y_batch = y[batch_size * j: batch_size * (j+1)]   # Get a mini-batch of target data y\n",
        " \n",
        "            dw = np.mean(gradient(x_batch, w, y_batch)) # Compute gradient estimates ∇L(w) \n",
        "            w = w - eta* dw  # Update parameters using the formula  w←w−η∇w\n",
        "            loss_sum += loss(h(x_batch, w), y_batch) # Sum up losses of mini-batches \n",
        "\n",
        "        if (i % 10) == 0:\n",
        "            loss_avg.append(loss_sum / num_batch) # Get average of mimi-batch loss\n",
        "\n",
        "    return w, loss_avg        \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Dataset\n",
        "    dataset = np.array([[.30,  0],\n",
        "                        [.90,  1],\n",
        "                        [.50,  0],\n",
        "                        [.65,  1],\n",
        "                        [.70,  1],\n",
        "                        [.40,  0]])\n",
        "\n",
        "    batch_size = 6  # Size of mini-batch data\n",
        "    num_batch = int(dataset.shape[0]/batch_size)  # Number of mini-batches\n",
        "    loss_avg = [] # Loss average\n",
        "\n",
        "    w, loss_avg = SGD(500)\n",
        "    print(f'Value of weight parameter w:{w: .4f}')\n",
        "    print(f'Prediction output with the score 60:{h(0.9863, 0.60): .4f}')  \n",
        "    \n",
        "    # Show the average loss of mini-batch\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    iter_count = range(1, len(loss_avg) + 1)\n",
        "    plt.plot(iter_count, loss_avg, 'b-')\n",
        "    plt.title('Loss vs iteration')\n",
        "    plt.legend(['Loss'])\n",
        "    plt.xlabel('Iteration x10')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "Qlj0TG63KeBE",
        "outputId": "7f11f6ac-fbbf-40c2-c075-f0d56886764e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of weight parameter w: 0.9843\n",
            "Prediction output with the score 60: 0.6438\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\"> After training, we have obtained the weight value 0.9843.  Applying this weight value and new score 60 to the hypothesis function, i.e, h(0.9843, 60), we get prediction output with a real value 0.6438. What does this value of 0.6438 imply ? How do we intrepret and get the meamingful prediction ? In order to answer these questions, we need to define a threshold for determing pass or fail based on the prediction output from the hypothesis function h(w,x). As in linear regression, the performance of loss vs iteration is shown. \n",
        "</p>"
      ],
      "metadata": {
        "id": "9LrKhNBknzkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Threshold for correct prediction\n",
        "<p align=\"justify\">We can see the prediction output values for the entire input data. In order to  set a proper value of threshold, we have used the average score of the dataset as a threshold value. As desribed in code below, with the average score to determine pass/fail of the dataset, the prediction is identical to pass/fail of the dataset. Applying this threshold for determiniing the pass/fail of the new score 60, it is found that the score 60 will pass the written test for the licence. You can experiment that the new score 55 will result in fail for the test. The setting proper threshold is essential to correct predition for the dataset.  In exercise, you can experment that the prediction is dependent on the threshold value.</p>"
      ],
      "metadata": {
        "id": "azjLp3LPk1DA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = h(dataset[:, 0], w) # get predicted output values for input data \n",
        "threshold = np.average(score) # get average of predicted output values\n",
        "# print(threshold)\n",
        "\n",
        "# Get prediction with threshold of average of output values. \n",
        "prediction = [1 if (score[i] > threshold) else 0 for i in range(len(score))] \n",
        "print('Prediction for the dataset with average threshold:', prediction)\n",
        "\n",
        "# Get prediction for new score x\n",
        "w, _ = SGD(500) \n",
        "x = 0.60\n",
        "#x = 0.55\n",
        "new_score = h(w, x)\n",
        "if new_score > threshold:\n",
        "  print(f'Score {x * 100: .1f} is predicted to pass the written test.')\n",
        "else:\n",
        "  print(f'Score {x * 100: .1f} is predicted to fail the written test.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3IU85YWmcSx",
        "outputId": "2ca30d6c-f974-4dc2-c512-587ff546983f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for the dataset with average threshold: [0, 1, 0, 1, 1, 0]\n",
            "Score  60.0 is predicted to pass the written test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: Get predictions by varing the treshold value to threshold+0.02, threshold-0.02 and others. "
      ],
      "metadata": {
        "id": "EOP7d06zoU8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get prediction with higher threshold  \n",
        "prediction_high = [1 if (score[i] > threshold+0.02) else 0 for i in range(len(score))] \n",
        "print(f'Prediction with higher treshold value: {prediction_high}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRYlqjD0wo6r",
        "outputId": "b6c97e69-81b1-4705-9c35-97ef43b30063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction with higher treshold value: [0, 1, 0, 0, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Peformance Metrics for Logistic Regression\n",
        "<p align=\"justify\"> There are different metrics to measure the performance of any classifier including binary classifier, i.e., the logistic regression. These metrics include confusion metrics, accuracy, precions, recall, specificity, F-1 score, and AUC-ROC curve. </p>\n",
        "<p align=\"justify\"> For the above example, the confusion matrix summarizes results such as true positive (1), true negative (0), false positive (1), and false negative (0). You may  refer to the reference[] for defition of these concept. The accuracy measures the faction of correct predictions. Precision measures the fraction of correct positive predictions from all the positive predictions. Recall measures the fraction of positive predictions from all the positive samples. Classfication report shows all these metrics together.</p>\n",
        "<p align=\"justify\"> For skewed dataset where only small portion of dataset samples is positive (or negative), the accuracy may not indicate correctly how good the performance is. In this case, precision and recall are important performance metrics. However, there is a tradoff betweem precision and recall, so that F-1 score is often used to compensate for the limitation of the accuracy for the skewed dataset.F-1 score is a weighted average of the precision and recall, where an F-1 score reaches its best at 1 and worst at 0.\n",
        "</p>\n",
        "<p align=\"justify\"> Below, we measure the performance of the model for logistic regression, using sklearn libraries.\n",
        "</p>"
      ],
      "metadata": {
        "id": "DuC72FZbr68F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "Y_actual = dataset[:, 1]\n",
        "Y_predic = prediction\n",
        "results = confusion_matrix(Y_actual, Y_predic)\n",
        "print ('Confusion Matrix :\\n', results)\n",
        "print ('Accuracy :', accuracy_score(Y_actual, Y_predic))\n",
        "print ('Classification Report : \\n', classification_report(Y_actual, Y_predic))\n",
        "\n",
        "Y_predic = prediction_high\n",
        "results = confusion_matrix(Y_actual, Y_predic)\n",
        "print ('Confusion Matrix :\\n', results)\n",
        "print ('Accuracy :', accuracy_score(Y_actual, Y_predic))\n",
        "print ('Classification Report : \\n', classification_report(Y_actual, Y_predic))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccy85yyM_N1T",
        "outputId": "55205550-b6fd-4c9e-9133-30f87fcdf416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix :\n",
            " [[3 0]\n",
            " [0 3]]\n",
            "Accuracy : 1.0\n",
            "Classification Report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         3\n",
            "         1.0       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         6\n",
            "   macro avg       1.00      1.00      1.00         6\n",
            "weighted avg       1.00      1.00      1.00         6\n",
            "\n",
            "Confusion Matrix :\n",
            " [[3 0]\n",
            " [1 2]]\n",
            "Accuracy : 0.8333333333333334\n",
            "Classification Report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      1.00      0.86         3\n",
            "         1.0       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.83         6\n",
            "   macro avg       0.88      0.83      0.83         6\n",
            "weighted avg       0.88      0.83      0.83         6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\"> We have tested with two prediction: prediction with threshod with average score, and another with a little higher threshold added with 0.02. In the first case, it is shown that the accuracy is 100 %  because the predicted output is identical to acutal y values [0, 1, 0, 1, 1, 0] of the dataset. In the confusion matrix, all the non-diagonal elements are zero. In the second case with higher threshold, the predicited output is [0, 1, 0, 0, 1, 0] so that there is one erroneus classfication. This results in the accuracy of 83 %, i.e., 5/6, and affects other metrics such as F-1 score, precision and recall. AUC-ROC is not shown here for simplicity of explanation. </p>"
      ],
      "metadata": {
        "id": "vYA_QqMByHiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete Code for Logistic Regression\n",
        "The complet code of logistic regression of the simple toy example is shown below."
      ],
      "metadata": {
        "id": "IG-CsHhTyF0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(45) # set the seed value\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\" Logistic function \"\"\"\n",
        "    return 1.0/(1+ np.exp(-x))\n",
        "\n",
        "def h(x, w):\n",
        "    \"\"\"Hypothesis function h(x) = sigmoid (x * w)\"\"\"\n",
        "    return sigmoid(x * w)\n",
        "\n",
        "def loss(o, y):\n",
        "    \"\"\"Cross-entropy error function\"\"\"\n",
        "    return -np.mean(y*np.log(o) + (1-y)*np.log(1-o)) # np.log is natural logarithm\n",
        "\n",
        "\n",
        "def gradient(x, w, y):\n",
        "    \"\"\"Gradient function\"\"\"\n",
        "    return x * (h(x, w) - y)\n",
        "\n",
        "def SGD(n_iter):\n",
        "    \"\"\" Mini-batch gradient descent optimization\"\"\"\n",
        "\n",
        "    # Initialize learning rate and weight \n",
        "    eta = 0.7 # learning rate\n",
        "    w = 0.05  # Initialize weight\n",
        "    data = dataset.copy() # get a copy of dataset for shuffling\n",
        "\n",
        "    # Perform mini-batch SGD optimization\n",
        "    for i in range(n_iter):\n",
        "\n",
        "        np.random.shuffle(data) # Randomize the dataset\n",
        "        x = data[:, 0] # Get input data\n",
        "        y = data[:, 1] # Get target data\n",
        "        loss_sum = 0  \n",
        "\n",
        "        for j in range(num_batch): # Iterate over mini-batches of dataset\n",
        "            x_batch = x[batch_size * j: batch_size * (j+1)]    # Get a mini-batch of input data x\n",
        "            y_batch = y[batch_size * j: batch_size * (j+1)]   # Get a mini-batch of target data y\n",
        "\n",
        "            dw = np.mean(gradient(x_batch, w, y_batch)) # Compute gradient estimates ∇L(w) \n",
        "            w = w - eta* dw  # Update parameters using the formula  w←w−η∇w\n",
        "            loss_sum += loss(h(x_batch, w), y_batch) # Sum up losses of mini-batches \n",
        "\n",
        "        if (i % 10) == 0:\n",
        "            loss_avg.append(loss_sum / num_batch) # Get average of mimi-batch loss\n",
        "\n",
        "    return w, loss_avg        \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Dataset\n",
        "    dataset = np.array([[.30,  0],\n",
        "                        [.90,  1],\n",
        "                        [.50,  0],\n",
        "                        [.65,  1],\n",
        "                        [.70,  1],\n",
        "                        [.40,  0]])\n",
        "\n",
        "    batch_size = 6  # Size of mini-batch data\n",
        "    num_batch = int(dataset.shape[0]/batch_size)  # Number of mini-batches\n",
        "    loss_avg = [] # Loss average\n",
        "\n",
        "    w, loss_avg = SGD(500)\n",
        "    print(f'Value of weight parameter w:{w: .4f}')\n",
        "    print(f'Prediction output with the score 60:{h(0.9863, 0.60): .4f}')  \n",
        "    \n",
        "    # Show the average loss of mini-batch\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    iter_count = range(1, len(loss_avg) + 1)\n",
        "    plt.plot(iter_count, loss_avg, 'b-')\n",
        "    plt.title('Loss vs iteration')\n",
        "    plt.legend(['Loss'])\n",
        "    plt.xlabel('Iteration x10')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "    score = h(dataset[:, 0], w) # get predicted output values for input data \n",
        "    threshold = np.average(score) # get average of predicted output values\n",
        "\n",
        "    # Get prediction with threshold of average of output values. \n",
        "    prediction = [1 if (score[i] > threshold) else 0 for i in range(len(score))] \n",
        "    print('Prediction for the dataset with average threshold:', prediction)\n",
        "\n",
        "    # Get prediction for new score x\n",
        "    w, _ = SGD(500) \n",
        "    x = 0.60\n",
        "    new_score = h(w, x)\n",
        "    if new_score > threshold:\n",
        "        print(f'Score {x * 100: .1f} is predicted to pass the written test.')\n",
        "    else:\n",
        "        print(f'Score {x * 100: .1f} is predicted to fail the written test.')\n",
        "\n",
        "    # Get prediction with higher threshold  \n",
        "    prediction_high = [1 if (score[i] > threshold+0.02) else 0 for i in range(len(score))] \n",
        "    print(f'Prediction with higher treshold value: {prediction_high}')\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "    Y_actual = dataset[:, 1]\n",
        "    Y_predic = prediction\n",
        "    results = confusion_matrix(Y_actual, Y_predic)\n",
        "    print ('Confusion Matrix :\\n', results)\n",
        "    print ('Accuracy :', accuracy_score(Y_actual, Y_predic))\n",
        "    print ('Classification Report : \\n', classification_report(Y_actual, Y_predic))\n",
        "\n",
        "    Y_predic = prediction_high\n",
        "    results = confusion_matrix(Y_actual, Y_predic)\n",
        "    print ('Confusion Matrix :\\n', results)\n",
        "    print ('Accuracy :', accuracy_score(Y_actual, Y_predic))\n",
        "    print ('Classification Report : \\n', classification_report(Y_actual, Y_predic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "VihLewy_NpfG",
        "outputId": "6280b7f5-d363-460e-a802-8c568e1c3074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of weight parameter w: 0.9843\n",
            "Prediction output with the score 60: 0.6438\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for the dataset with average threshold: [0, 1, 0, 1, 1, 0]\n",
            "Score  60.0 is predicted to pass the written test.\n",
            "Prediction with higher treshold value: [0, 1, 0, 0, 1, 0]\n",
            "Confusion Matrix :\n",
            " [[3 0]\n",
            " [0 3]]\n",
            "Accuracy : 1.0\n",
            "Classification Report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         3\n",
            "         1.0       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         6\n",
            "   macro avg       1.00      1.00      1.00         6\n",
            "weighted avg       1.00      1.00      1.00         6\n",
            "\n",
            "Confusion Matrix :\n",
            " [[3 0]\n",
            " [1 2]]\n",
            "Accuracy : 0.8333333333333334\n",
            "Classification Report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      1.00      0.86         3\n",
            "         1.0       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.83         6\n",
            "   macro avg       0.88      0.83      0.83         6\n",
            "weighted avg       0.88      0.83      0.83         6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercise: Implement logistic regression with Python and Keras/Tensorflow."
      ],
      "metadata": {
        "id": "mbC-uQ9GvVsY"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "name": "LogisticRegression_Practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}